from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv
import os
from services.data import query_data
from services.context import get_context_manager
from services.response_parser import get_response_parser
from prompts.prompts import CHAT_PROMPT

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
model = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0, google_api_key=api_key)

def get_response(message: str, video_id: str = None, session_id: str = "default") -> str:
    try:
        print(f"ğŸ¤– get_response called with message: '{message}', video_id: '{video_id}', session_id: '{session_id}'")
        
        # Láº¥y context manager
        context_mgr = get_context_manager()
        
        # Láº¥y lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n
        conversation_history = context_mgr.get_context_summary(session_id, video_id)
        print(f"ğŸ“š Conversation history length: {len(conversation_history)} chars")
        
        # Chuáº©n bá»‹ subtitles
        subtitle_text = ""
        if video_id:
            # TÃ¬m kiáº¿m subtitles tá»« database
            print(f"ğŸ” Searching for video_id: {video_id}")
            subtitles = query_data(message, video_id=video_id)
            print(f"ğŸ“Š Found {len(subtitles)} subtitles")
            
            if subtitles:
                # Format subtitles thÃ nh text vá»›i timestamp
                subtitle_lines = []
                for sub in subtitles:
                    text = sub.get("text", "")
                    metadata = sub.get("metadata", {})
                    start_time = metadata.get("start_time", "")
                    end_time = metadata.get("end_time", "")
                    
                    # Sá»­ dá»¥ng format timestamp gá»‘c Ä‘á»ƒ chat cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh má»‘c thá»i gian tá»‘t hÆ¡n
                    if start_time is not None and start_time != "":
                        # Náº¿u lÃ  format h:mm:ss.ms, giá»¯ nguyÃªn
                        if ':' in str(start_time):
                            time_str = f"[{start_time}]"
                        # Náº¿u lÃ  milliseconds, convert sang format dá»… Ä‘á»c
                        elif str(start_time).isdigit():
                            start_time_num = float(start_time)
                            start_minutes = int(start_time_num) // 60000
                            start_seconds = (int(start_time_num) % 60000) // 1000
                            time_str = f"[{start_minutes}:{start_seconds:02d}]"
                        else:
                            time_str = f"[{start_time}]"
                    else:
                        time_str = "[?:??]"
                    
                    subtitle_lines.append(f"{time_str} {text}")
                
                subtitle_text = "\n".join(subtitle_lines)
                print(f"ğŸ“ Using subtitles for context (length: {len(subtitle_text)} chars)")
            else:
                print("âš ï¸ No subtitles found for this video_id")
                subtitle_text = "KhÃ´ng tÃ¬m tháº¥y subtitles cho video nÃ y."
        else:
            print("ğŸ’¬ No video_id provided, using general response")
        
        # Sá»­ dá»¥ng prompt chung cho cáº£ 2 trÆ°á»ng há»£p
        formatted_prompt = CHAT_PROMPT.format(
            context=message,
            subtitles=subtitle_text,
            conversation_history=conversation_history or "ChÆ°a cÃ³ lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n."
        )
        
        response = model.invoke(formatted_prompt)
        response_content = response.content
        
        # LuÃ´n parse response thÃ nh JSON
        parser = get_response_parser()
        parsed_data = parser.parse_response(response_content, question=message, video_id=video_id)
        
        # Validate parsed data
        if parser.validate_response(parsed_data):
            print(f"âœ… Response parsed successfully")
            json_response = parser.to_json(parsed_data)
            
            # LÆ°u vÃ o context vá»›i raw response
            context_mgr.add_message(session_id, message, response_content, video_id)
            print(f"ğŸ’¾ Saved to context for session: {session_id}")
            
            return json_response
        else:
            print(f"âš ï¸ Response validation failed, returning raw response")
            # Fallback: tráº£ vá» raw response
            context_mgr.add_message(session_id, message, response_content, video_id)
            return response_content
        
    except Exception as e:
        print(f"âŒ Error in get_response: {e}")
        # Fallback: tráº£ lá»i cÃ¢u há»i mÃ  khÃ´ng cáº§n subtitles
        try:
            fallback_prompt = CHAT_PROMPT.format(
                context=message,
                subtitles="",
                conversation_history=""
            )
            response = model.invoke(fallback_prompt)
            response_content = response.content
            
            # LuÃ´n parse response thÃ nh JSON
            parser = get_response_parser()
            parsed_data = parser.parse_response(response_content, question=message, video_id=video_id)
            if parser.validate_response(parsed_data):
                json_response = parser.to_json(parsed_data)
                context_mgr = get_context_manager()
                context_mgr.add_message(session_id, message, response_content, video_id)
                return json_response
            
            # Váº«n lÆ°u vÃ o context ngay cáº£ khi cÃ³ lá»—i
            context_mgr = get_context_manager()
            context_mgr.add_message(session_id, message, response_content, video_id)
            
            return response_content
        except Exception as fallback_error:
            error_msg = f"Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y. Lá»—i: {str(fallback_error)}"
            return f'{{"error": "{error_msg}", "parsed_successfully": false}}'