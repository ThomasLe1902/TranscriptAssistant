import os
from dotenv import load_dotenv
from typing import List, Dict, Any
import uuid

load_dotenv()
pinecone_api_key = os.getenv("PINECONE_API_KEY")

# Global model variable
_model = None
_use_mock = False

def get_model():
    """Lazy loading c·ªßa sentence transformer model"""
    global _model, _use_mock
    if _model is None and not _use_mock:
        try:
            from sentence_transformers import SentenceTransformer
            _model = SentenceTransformer('all-MiniLM-L6-v2')
            print("‚úÖ Using sentence-transformers model")
        except ImportError:
            print("‚ö†Ô∏è sentence-transformers not found, using mock embeddings")
            _use_mock = True
    return _model

def create_mock_embedding(text: str) -> List[float]:
    """T·∫°o mock embedding 384 dimensions (t∆∞∆°ng th√≠ch v·ªõi all-MiniLM-L6-v2)"""
    import random
    text_hash = hash(text) % (2**32)
    random.seed(text_hash)
    embedding = [random.random() for _ in range(384)]
    random.seed()
    return embedding

def create_embedding(text: str) -> List[float]:
    """
    T·∫°o embedding s·ª≠ d·ª•ng all-MiniLM-L6-v2 model ho·∫∑c mock
    """
    if _use_mock:
        return create_mock_embedding(text)
    
    model = get_model()
    if model is None:
        return create_mock_embedding(text)
    
    embedding = model.encode(text)
    return embedding.tolist()

def insert_data(texts: List[str], metadatas: List[Dict[str, Any]]):
    """
    Vector h√≥a v√† l∆∞u texts v√†o Pinecone
    """
    try:
        # Import Pinecone client
        from pinecone import Pinecone
        
        # Initialize Pinecone
        pc = Pinecone(api_key=pinecone_api_key)
        index = pc.Index("subtitles")
        
        vectors_to_upsert = []
        for i, (text, metadata) in enumerate(zip(texts, metadatas)):
            embedding = create_embedding(text)
            vector_id = str(uuid.uuid4())
            vector = {
                "id": vector_id,
                "values": embedding,
                "metadata": {
                    **metadata,
                    "text": text  # Th√™m text v√†o metadata ƒë·ªÉ query
                }
            }
            vectors_to_upsert.append(vector)
        
        batch_size = 100
        for i in range(0, len(vectors_to_upsert), batch_size):
            batch = vectors_to_upsert[i:i + batch_size]
            index.upsert(vectors=batch)
        
        return index
        
    except Exception as e:
        if "No active indexes found" in str(e) or "not found" in str(e).lower():
            raise Exception("Pinecone index 'subtitles' not found. Please create it first.")
        else:
            raise e

def query_data(query: str, k: int = 5, video_id: str = None) -> List[Dict[str, Any]]:
    """
    T√¨m ki·∫øm semantic trong Pinecone
    
    Args:
        query: C√¢u h·ªèi t√¨m ki·∫øm
        k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ tr·∫£ v·ªÅ
        video_id: ID video ƒë·ªÉ filter (optional)
    """
    try:
        # Import Pinecone client
        from pinecone import Pinecone
        
        # Initialize Pinecone
        pc = Pinecone(api_key=pinecone_api_key)
        index = pc.Index("subtitles")
        
        # T·∫°o embedding cho query
        query_embedding = create_embedding(query)
        
        # Chu·∫©n b·ªã filter v·ªõi syntax ƒë√∫ng cho Pinecone
        filter_dict = None
        if video_id:
            filter_dict = {"video_id": {"$eq": video_id}}
            print(f"üîç Querying with video_id filter: {video_id}")
        else:
            print("üîç Querying without video_id filter")
        
        # T√¨m ki·∫øm
        results = index.query(
            vector=query_embedding,
            top_k=k,
            include_metadata=True,
            filter=filter_dict
        )
        
        # Format k·∫øt qu·∫£ v√† debug
        formatted_results = []
        for match in results.matches:
            match_video_id = match.metadata.get("video_id", "unknown")
            print(f"üìù Found match with video_id: {match_video_id}, score: {match.score:.3f}")
            formatted_results.append({
                "text": match.metadata.get("text", ""),
                "metadata": match.metadata,
                "similarity_score": float(match.score)
            })
        
        print(f"‚úÖ Total results found: {len(formatted_results)}")
        return formatted_results
        
    except Exception as e:
        print(f"‚ùå Error in query_data: {e}")
        return []

def get_stats() -> Dict[str, Any]:
    """
    L·∫•y th·ªëng k√™ v·ªÅ vector store
    """
    try:
        from pinecone import Pinecone
        pc = Pinecone(api_key=pinecone_api_key)
        index = pc.Index("subtitles")
        stats = index.describe_index_stats()
        return {
            "total_vectors": stats.total_vector_count,
            "dimension": stats.dimension,
            "index_fullness": stats.index_fullness
        }
    except Exception as e:
        return {}

def wipe_database() -> Dict[str, Any]:
    """
    X√≥a t·∫•t c·∫£ records trong index
    """
    try:
        from pinecone import Pinecone
        pc = Pinecone(api_key=pinecone_api_key)
        index = pc.Index("subtitles")
        
        # L·∫•y th·ªëng k√™ tr∆∞·ªõc khi x√≥a
        stats_before = index.describe_index_stats()
        total_before = stats_before.total_vector_count
        
        # X√≥a t·∫•t c·∫£ vectors
        index.delete(delete_all=True)
        
        # L·∫•y th·ªëng k√™ sau khi x√≥a
        stats_after = index.describe_index_stats()
        total_after = stats_after.total_vector_count
        
        return {
            "success": True,
            "deleted_vectors": total_before,
            "remaining_vectors": total_after,
            "message": f"Successfully deleted {total_before} vectors from database"
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": "Failed to wipe database"
        }

